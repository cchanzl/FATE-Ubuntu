{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sksurv.metrics import concordance_index_censored as ci_scikit\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# to change path when new data is extracted\n",
    "jobid=\"job_20210716154134347324201_homo_secureboost\"  # change this to update output from FL model (job_20210716145243808000193)\n",
    "jobid_sbt_predict=\"job_20210716144019624912192_homo_secureboost\"\n",
    "jobid_class=\"job_20210716125240195211146_homo_nn\"\n",
    "\n",
    "party_A=\"_0_guest_1234_output_data\"\n",
    "party_B=\"_0_host_2222_output_data\"\n",
    "party_C=\"_0_host_3333_output_data\"\n",
    "\n",
    "full_path=\"C:/Users/chanzl_thinkpad/Dropbox/Imperial/Individual Project/NASA/survival-analysis-nasa/\"\n",
    "central_test_results=\"C:/Users/chanzl_thinkpad/Dropbox/Imperial/Individual Project/NASA/survival-analysis-nasa/graphing.csv\"\n",
    "filename = \"data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A=pd.read_csv(os.path.join(jobid+party_A, filename))\n",
    "df_B=pd.read_csv(os.path.join(jobid+party_B, filename))\n",
    "df_C=pd.read_csv(os.path.join(jobid+party_C, filename))\n",
    "\n",
    "df_A_sbt_predict=pd.read_csv(os.path.join(jobid_sbt_predict+party_A, filename))\n",
    "df_B_sbt_predict=pd.read_csv(os.path.join(jobid_sbt_predict+party_B, filename))\n",
    "df_C_sbt_predict=pd.read_csv(os.path.join(jobid_sbt_predict+party_C, filename))\n",
    "\n",
    "df_A_class=pd.read_csv(os.path.join(jobid_class+party_A, filename))\n",
    "df_B_class=pd.read_csv(os.path.join(jobid_class+party_B, filename))\n",
    "df_C_class=pd.read_csv(os.path.join(jobid_class+party_C, filename))\n",
    "\n",
    "graph_data=pd.read_csv(central_test_results)\n",
    "\n",
    "test_clipped = pd.read_csv(full_path + 'Dataset/processed/test_clipped.csv')\n",
    "train_clipped = pd.read_csv(full_path + 'Dataset/processed/train_clipped.csv')\n",
    "\n",
    "test_trend = pd.read_csv(full_path + 'Dataset/processed/rul_FL_test_trended_cluster.csv')\n",
    "train_trend = pd.read_csv(full_path + 'Dataset/processed/rul_FL_train_trended_cluster.csv')\n",
    "list_results = pd.read_excel(full_path + 'results/saved_results_16-07-2021_100012.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_FL_output(df, type=\"regression\"):\n",
    "    df['cycle'] = 0\n",
    "    df['unit num'] = 0\n",
    "    if type == \"train\":\n",
    "        df.loc[df['type'] == \"train\", \"cycle\"] = df.id % 100\n",
    "        df.loc[df['type'] == \"validate\", \"cycle\"] = df.id % 100\n",
    "        df.loc[df['type'] == \"predict\", \"cycle\"] = df.id % 100000\n",
    "        \n",
    "        # retrieve unit num\n",
    "        df.loc[df['type'] == \"train\", \"unit num\"] = (df['id'] - df['cycle']) / 100\n",
    "        df.loc[df['type'] == \"validate\", \"unit num\"] = (df['id'] - df['cycle']) / 100\n",
    "        df.loc[df['type'] == \"predict\", \"unit num\"] = (df['id'] - df['cycle']) / 100000\n",
    "    else:\n",
    "        df[\"cycle\"] = df.id % 100000\n",
    "        df[\"unit num\"] = (df['id'] - df['cycle']) / 100000\n",
    "    \n",
    "    df['unit num'] = df['unit num'].astype(int)\n",
    "    df.rename(columns={'predict_result': 'y_hat'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_test_result(df_temp, df_main, L=20):\n",
    "    interim_result = df_main.copy()\n",
    "    interim_result['y_hat'] = 0\n",
    "    count = 0\n",
    "    for engine in interim_result['unit num'].unique():\n",
    "        # get first and last index position of each set of engine\n",
    "        first_idx = interim_result['unit num'].eq(engine).idxmax()\n",
    "        last_idx = interim_result['unit num'].eq(engine+1).idxmax()-1\n",
    "        if last_idx == -1:\n",
    "            last_idx = len(interim_result)-1\n",
    "\n",
    "        # populate RUL for middle cycles\n",
    "        while (last_idx - first_idx) >= L-1:\n",
    "            mid_idx = first_idx + L - 1\n",
    "            interim_result.iat[mid_idx, -1] = df_temp.iloc[count]['y_hat']\n",
    "            anchor_up = df_temp.iloc[count]['y_hat']\n",
    "            anchor_down = df_temp.iloc[count]['y_hat']\n",
    "            count += 1\n",
    "            first_idx += L\n",
    "            for offset in range(1, L):\n",
    "                interim_result.iat[mid_idx-offset, -1] = anchor_up + 1\n",
    "                anchor_up += 1\n",
    "\n",
    "        # populate RUL for remaining cycles\n",
    "        for offset in range(1, last_idx-mid_idx+1):\n",
    "            interim_result.iat[mid_idx + offset, -1] = anchor_down - 1\n",
    "            anchor_down -= 1\n",
    "\n",
    "    return interim_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nasaScore(RUL_true, RUL_hat):\n",
    "    d = RUL_hat - RUL_true\n",
    "    score = 0\n",
    "    for i in d:\n",
    "        if i >= 0:\n",
    "            score += np.math.exp(i / 13) - 1\n",
    "        else:\n",
    "            score += np.math.exp(- i / 10) - 1\n",
    "    return score/len(RUL_true)  # should the score be averaged?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph(df, selected_unit_num):\n",
    "    fig, axs = plt.subplots(int(len(selected_unit_num)/2), 2)\n",
    "    models = ['RUL', 'NN (tuned trended)', 'RF (trended)', 'FL-GBDT (Trended)', \n",
    "              'FL-NN (Trended classification)', 'NN (tuned trended classification)']\n",
    "    i = -1\n",
    "    for ax in axs.flatten():\n",
    "        i += 1\n",
    "        df_graph = df[df['unit num'] == selected_unit_num[i]]\n",
    "        ax.set_title('Test engine ' + str(selected_unit_num[i]))\n",
    "        for col in models:\n",
    "            if col == 'RUL':\n",
    "                ax.plot(df_graph['cycle'], df_graph[col], label=col, linestyle='dashed', linewidth=0.75)\n",
    "            else:\n",
    "                ax.plot(df_graph['cycle'], df_graph[col], label=col, linewidth=0.75)\n",
    "    plt.xlabel('Cycles')\n",
    "    plt.ylabel('RUL')\n",
    "    plt.legend(fontsize=14) # using a size in points\n",
    "    # plt.rcParams[\"figure.figsize\"] = (200,30)  # width x height\n",
    "    # plt.figure(figsize=(50,10))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, df_result, label='test'):\n",
    "    \"\"\" Evaluates model output on rmse, R2 and C-Index\n",
    "    Args:\n",
    "    model (string): name of model for documentation\n",
    "    df_result (pandas.df): dataframe with the headers 'unit num', 'RUL', 'y_hat', 'breakdown'\n",
    "    label (string): type of output (train or test)\n",
    "\n",
    "    Returns:\n",
    "    list: returns [model, label, rmse, ci_sk, variance]\n",
    "    \"\"\"\n",
    "\n",
    "    y_true = df_result['RUL']\n",
    "    y_hat = df_result['y_hat']\n",
    "    df_result['breakdown'].replace(0, False, inplace=True)  # rsf only takes true or false\n",
    "    df_result['breakdown'].replace(1, True, inplace=True)  # rsf only takes true or false\n",
    "\n",
    "    mse = mean_squared_error(y_true, y_hat)\n",
    "    rmse = np.sqrt(mse)\n",
    "    variance = r2_score(y_true, y_hat)\n",
    "\n",
    "    # the concordance index (CI) is interested on the order of the predictions, not the predictions themselves\n",
    "    # CI can only be measured between individual samples where a censoring or failure event occurred\n",
    "    # https://medium.com/analytics-vidhya/concordance-index-72298c11eac7#:~:text=The%20concordance%20index%20or%20c,this%20definition%20mean%20in%20practice\n",
    "    df_result_grouped = df_result.groupby('unit num').last()\n",
    "    breakdown = df_result_grouped['breakdown']\n",
    "    y_true = df_result_grouped['RUL']\n",
    "    y_hat = df_result_grouped['y_hat']\n",
    "    ci_sk = ci_scikit(breakdown, y_true, y_hat)[0]\n",
    "    score = nasaScore(y_true, y_hat)  # score should be based on the last instance\n",
    "    print('{} set RMSE:{:.2f}, Score:{:.2f}, CI(scikit):{:.4f}, R2:{:.2f}'.format(label, rmse, score, ci_sk, variance))\n",
    "    result = [model, label, rmse, score, ci_sk, variance]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_final_RUL(df, column):\n",
    "    # to show avg cycle at which event occurred\n",
    "    final_rul = []\n",
    "    for i in range(1, 101):\n",
    "        df_engine = df[df['unit num'] == i]\n",
    "        max_cycle = df_engine.loc[df_engine[column].idxmin()]\n",
    "        final_rul.append(max_cycle[column].astype(int))\n",
    "    return final_rul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting federated output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_FL_output(df_A)\n",
    "format_FL_output(df_B)\n",
    "format_FL_output(df_C)\n",
    "\n",
    "format_FL_output(df_A_sbt_predict)\n",
    "format_FL_output(df_B_sbt_predict)\n",
    "format_FL_output(df_C_sbt_predict)\n",
    "\n",
    "format_FL_output(df_A_class, \"classification\")\n",
    "format_FL_output(df_B_class, \"classification\")\n",
    "format_FL_output(df_C_class, \"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_master_FL = df_A.copy()\n",
    "df_master_FL=df_master_FL.append(df_B)\n",
    "df_master_FL=df_master_FL.append(df_C)\n",
    "df_master_FL.sort_values(['id'], ascending=[True], inplace=True)\n",
    "\n",
    "df_master_FL_sbt_predict = df_A_sbt_predict.copy()\n",
    "df_master_FL_sbt_predict=df_master_FL_sbt_predict.append(df_B_sbt_predict)\n",
    "df_master_FL_sbt_predict=df_master_FL_sbt_predict.append(df_C_sbt_predict)\n",
    "df_master_FL_sbt_predict.sort_values(['id'], ascending=[True], inplace=True)\n",
    "\n",
    "df_master_FL_class = df_A_class.copy()\n",
    "df_master_FL_class = df_master_FL_class.append(df_B_class)\n",
    "df_master_FL_class = df_master_FL_class.append(df_C_class)\n",
    "df_master_FL_class.sort_values(['id'], ascending=[True], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chanzl_thinkpad\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\chanzl_thinkpad\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# drop rows that are train for regression results\n",
    "df_train_FL = df_master_FL[df_master_FL.type == \"train\"]\n",
    "df_test_FL = df_master_FL[df_master_FL.type == \"validate\"]\n",
    "\n",
    "# sort\n",
    "df_train_FL.sort_values(['unit num', 'cycle'], ascending=[True, True], inplace=True)\n",
    "df_test_FL.sort_values(['unit num', 'cycle'], ascending=[True, True], inplace=True)\n",
    "df_master_FL_sbt_predict.sort_values(['unit num', 'cycle'], ascending=[True, True], inplace=True)\n",
    "df_master_FL_class.sort_values(['unit num', 'cycle'], ascending=[True, True], inplace=True)\n",
    "\n",
    "# reset index\n",
    "df_train_FL.reset_index(inplace=True)\n",
    "df_test_FL.reset_index(inplace=True)\n",
    "df_master_FL_sbt_predict.reset_index(inplace=True)\n",
    "df_master_FL_class.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_test_FL.to_excel(\"TEST.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding back prediction back for graphing.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-7a5b77e3d129>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_trend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf_temp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_hat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_test_FL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_hat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf_result_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_test_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_temp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_clipped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdf_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_trend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-0a0c0d84c097>\u001b[0m in \u001b[0;36mmap_test_result\u001b[1;34m(df_temp, df_main, L)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlast_idx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfirst_idx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mmid_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfirst_idx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mL\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0minterim_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmid_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_hat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0manchor_up\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_hat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0manchor_down\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_temp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_hat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2116\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Not enough indexers for scalar access (setting)!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2118\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_value\u001b[1;34m(self, index, col, value, takeable)\u001b[0m\n\u001b[0;32m   3263\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtakeable\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3264\u001b[0m                 \u001b[0mseries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3265\u001b[1;33m                 \u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3266\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_set_value\u001b[1;34m(self, label, value, takeable)\u001b[0m\n\u001b[0;32m   1068\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1070\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1071\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "# adding back regression results\n",
    "df_temp = test_trend.copy()\n",
    "df_temp['y_hat']=df_test_FL['y_hat']\n",
    "df_result_test = map_test_result(df_temp, test_clipped)\n",
    "\n",
    "df_temp = train_trend.copy()\n",
    "df_temp['y_hat']=df_train_FL['y_hat']\n",
    "df_result_train = map_test_result(df_temp, train_clipped)\n",
    "\n",
    "graph_data['FL-GBDT (Trended)'] = df_result_test['y_hat']\n",
    "graph_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding back prediction results\n",
    "df_temp = test_trend.copy()\n",
    "df_temp['y_hat'] = df_master_FL_sbt_predict['y_hat']\n",
    "df_result_sbt_predict = map_test_result(df_temp, test_clipped)\n",
    "graph_data['FL-sbt (predict)'] = df_result_sbt_predict['y_hat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding back classification results\n",
    "df_temp = test_trend.copy()\n",
    "df_temp['y_hat'] = df_master_FL_class['y_hat']\n",
    "df_temp['y_hat'] = df_temp['y_hat'] * 10 + 5\n",
    "df_result_class = map_test_result(df_temp, test_clipped)\n",
    "graph_data['FL-NN (Trended classification)'] = df_result_class['y_hat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "make_graph(graph_data, [31, 38, 78, 91, 5, 46, 55, 82])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_failure = return_final_RUL(graph_data, 'RUL')\n",
    "rf_failure = return_final_RUL(graph_data, 'RF (trended)')\n",
    "FL_failure = return_final_RUL(graph_data, 'FL-GBDT (Trended)')\n",
    "FL_class_failure = return_final_RUL(graph_data, 'FL-NN (Trended classification)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "axes[0].scatter(range(1, 101), ori_failure, marker='o')\n",
    "\n",
    "axes[0].plot(range(1, 101), [stats.describe(ori_failure)[2]]*100, linestyle='dashed', \n",
    "             linewidth = 0.75, label='mean failure cycle (Original)')\n",
    "axes[0].plot(range(1, 101), [stats.describe(rf_failure)[2]]*100, linestyle='dashed', \n",
    "             linewidth = 0.75, label='mean failure cycle (Random forest)')\n",
    "axes[0].plot(range(1, 101), [stats.describe(FL_failure)[2]]*100, linestyle='dashed', \n",
    "             linewidth = 0.75, label='mean failure cycle (Federated learning - reg)')\n",
    "axes[0].plot(range(1, 101), [stats.describe(FL_class_failure)[2]]*100, linestyle='dashed', \n",
    "             linewidth = 0.75, label='mean failure cycle (Federated learning - class)')\n",
    "\n",
    "axes[0].set_xlabel(\"Engine Number\")\n",
    "axes[0].set_ylabel(\"Cycle at failure or censored event\")\n",
    "axes[0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), ncol=1)\n",
    "\n",
    "ax = sns.distplot(ori_failure, hist=True, kde=True, \n",
    "             bins=int(180/5), color = 'darkblue', \n",
    "             hist_kws={'edgecolor':'black'}, label=\"true distribution\",\n",
    "             kde_kws={'linewidth': 1.5}, ax=axes[1])\n",
    "ax = sns.distplot(rf_failure, hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'orange', \n",
    "             hist_kws={'edgecolor':'black'}, label=\"RF\",\n",
    "             kde_kws={'linewidth': 1.5}, ax=axes[1])\n",
    "ax = sns.distplot(FL_failure, hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'red', \n",
    "             hist_kws={'edgecolor':'black'}, label=\"FL GBDT\",\n",
    "             kde_kws={'linewidth': 1.5}, ax=axes[1])\n",
    "ax = sns.distplot(FL_class_failure, hist=False, kde=True, \n",
    "             bins=int(180/5), color = 'cyan', \n",
    "             hist_kws={'edgecolor':'black'}, label=\"FL NN\",\n",
    "             kde_kws={'linewidth': 1.5}, ax=axes[1])\n",
    "\n",
    "ax.set(xlabel=\"Cycle at failure or censored event\", ylabel='Density')\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), ncol=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "dict_boxplot = {'Original': ori_failure, 'Random Forest': rf_failure, \n",
    "                'FL GBDT': FL_failure, 'FL NN Classification': FL_class_failure} \n",
    "\n",
    "df_boxplot = pd.melt(pd.DataFrame(dict_boxplot))\n",
    "df_boxplot.rename(columns={'variable': 'selected model', 'value': 'cycle'}, inplace=True)\n",
    "ax = sns.boxplot(y=\"selected model\", x=\"cycle\", data=df_boxplot, boxprops=dict(alpha=.3))\n",
    "ax = sns.swarmplot(y=\"selected model\", x=\"cycle\", data=df_boxplot, color=\".25\")\n",
    "# ax.axes.set_title(\"Boxplot of RUL at final cycle - actual vs random forest vs federated model\",fontsize=12)\n",
    "ax.set_ylabel(\"Selected Models\",fontsize=12)\n",
    "ax.set_xlabel(\"Remaining Useful Life (RUL) at final cycle\",fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating RMSE and add to total result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_results.drop('timestamp', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = evaluate(\"FL-GBDT (Validate)\", df_result_test, 'test')\n",
    "test_temp = pd.DataFrame([test_result])\n",
    "test_temp.columns=['model_name', \"train_test\", 'RMSE', 'Score', 'CI_SK', 'R2']\n",
    "list_results=list_results.append(test_temp, ignore_index=True)\n",
    "test_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = evaluate(\"FL-GBDT (Predict)\", df_result_sbt_predict, 'test')\n",
    "test_temp = pd.DataFrame([test_result])\n",
    "test_temp.columns=['model_name', \"train_test\", 'RMSE', 'Score', 'CI_SK', 'R2']\n",
    "list_results=list_results.append(test_temp, ignore_index=True)\n",
    "test_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = evaluate('FL-NN (Trended classification)', df_result_class, 'test')\n",
    "test_temp = pd.DataFrame([test_result])\n",
    "test_temp.columns=['model_name', \"train_test\", 'RMSE', 'Score', 'CI_SK', 'R2']\n",
    "list_results=list_results.append(test_temp, ignore_index=True)\n",
    "test_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = evaluate(\"FL-GBDT (Train)\", df_result_train, 'train')\n",
    "train_temp = pd.DataFrame([train_result])\n",
    "train_temp.columns=['model_name', \"train_test\", 'RMSE', 'Score', 'CI_SK', 'R2']\n",
    "list_results=list_results.append(train_temp, ignore_index=True)\n",
    "train_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_results.sort_values(['train_test', 'RMSE'], ascending=[True, True], inplace=True)\n",
    "list_results.reset_index(inplace=True, drop=True)\n",
    "list_results.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
